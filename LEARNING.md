# 📚 데이터 관리자 학습 노트

1. 데이터 파이프라인 기초 (Phase 01-05)
주요 작업: 데이터 로드, 전처리 및 병합

[한 줄 해설]: 흩어진 여러 테이블을 키(ID) 기준으로 결합하여 분석 가능한 단일 소스로 만드는 공정.

[실무자 꿀팁]

[상] 파일 확인 습관: 코드 실행 전 ls 명령어로 소스 파일 존재 여부를 반드시 확인하십시오.

[상] 데이터 타입 검수: object를 datetime으로 변환하는 과정이 모든 시계열 분석의 기초입니다.

[상] 결측치 전략: fillna 시 비즈니스 논리에 맞는 값을 채워 데이터 왜곡을 방지해야 합니다.

2. 고객 분석 및 추천 엔진 (Phase 06-10)
주요 작업: 연관 분석(Apriori), RFM 세그먼테이션

[한 줄 해설]: 구매 패턴을 읽어 연관 상품을 추천하고, 고객을 등급별로 나누어 매출 기여도를 파악함.

[실무자 꿀팁]

[상] 데이터 지속성 확보: 분석 결과를 반드시 to_csv()로 저장해야 다음 단계에서 재료로 쓸 수 있습니다.

[상] Lift(향상도) 해석: Lift가 1보다 높아야 의미 있는 연관성입니다.

[중] 스토리텔링: 보고 시 frozenset 대신 "홈 인테리어와 침구류의 연관 구매"처럼 비즈니스 언어를 사용하세요.

3. 머신러닝 및 미래 예측 (Phase 11-13)
주요 작업: 이탈 예측(Churn), 시계열 수요 예측(Holt-Winters)

[한 줄 해설]: 과거 데이터를 학습시켜 누가 떠날지, 미래에 얼마가 팔릴지 예측하는 AI 아키텍처 구축.

[실무자 꿀팁]

[상] 데이터 불균형 해결: 이탈자가 적을 땐 class_weight='balanced'를 써서 모델의 편향을 막아야 합니다.

[상] 로그 변환(Log-Transform): 매출 예측 시 수치가 0 이하로 떨어지는 오류는 로그 함수로 해결합니다.

[상] 데이터 정제: 수집이 중단된 '절벽 구간' 데이터를 잘라내야 모델이 오판하지 않습니다.

[중] 디버깅: KeyError 발생 시 print(df.columns)로 컬럼 존재 여부를 먼저 확인하세요.

4. 검증 및 시각화 (Phase 14-16)
주요 작업: A/B 테스트 시뮬레이션, Streamlit 웹 대시보드

[한 줄 해설]: 제안한 전략을 통계적으로 검증하고, 이를 누구나 클릭 가능한 웹 앱으로 구현.

[실무자 꿀팁]

[상] 전용 실행기 사용: Streamlit은 반드시 streamlit run 파일명.py 명령어로 가동해야 합니다.

[상] p-value 확인: 0.05보다 작아야 우리의 전략이 '운'이 아닌 '실력'임을 증명할 수 있습니다.

[상] 버전 관리: 작업 종료 후 git add . → commit → push는 시니어의 기본 덕목입니다.

[중] 로그 제어: warnings.filterwarnings('ignore')로 노이즈를 제거해 결과에 집중하세요.

실무에서는 이를 **'원자적 커밋(Atomic Commit)'**이라고 합니다. 하나의 작업 단위(프로젝트 완수)가 끝날 때마다 상태를 저장하여, 언제든 과거의 성공 지점으로 돌아갈 수 있는 '타임머신'을 구축하는 설계 행위입니다.

📌 [시니어의 꿀팁]
꿀팁 1 (확인 습관): git push 후에 GitHub 웹사이트에 접속해서 LEARNING.md가 방금 수정한 내용으로 예쁘게 나오는지 꼭 확인해 보세요. 그게 최고의 보람입니다.

꿀팁 2 (상태 체크): 명령어를 입력하기 전에 git status를 쳐보세요. 어떤 파일들이 새로 생겼고 수정되었는지 빨간색/초록색으로 친절하게 알려줍니다.